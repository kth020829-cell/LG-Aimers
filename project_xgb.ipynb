{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38f5c56c",
   "metadata": {},
   "source": [
    "# XGBoost (with Optuna tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22824d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789efbd0-4cb3-49db-9d5f-60e6863cfb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train/train.csv').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dab0062a-cc94-43e9-934a-fcdafba486b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df, weather_df=None):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import holidays\n",
    "    from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "    # 1) 기본 전처리\n",
    "    df[['영업장명', '메뉴명']] = df['영업장명_메뉴명'].str.extract(r'^([^_ ]+)[_ ](.+)$')\n",
    "    df['영업일자'] = pd.to_datetime(df['영업일자'], errors='coerce')\n",
    "    df['year'] = df['영업일자'].dt.year\n",
    "    df['month'] = df['영업일자'].dt.month\n",
    "    df['day'] = df['영업일자'].dt.day\n",
    "    df['weekday'] = df['영업일자'].dt.weekday\n",
    "    df['day_of_year'] = df['영업일자'].dt.dayofyear\n",
    "    df['dow_month'] = df['weekday'].astype(str) + '_' + df['month'].astype(str)\n",
    "\n",
    "    # 2) 주기/사인코사인\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day'] / 28)\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day'] / 28)\n",
    "    df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 7)\n",
    "    df['weekday_cos'] = np.cos(2 * np.pi * df['weekday'] / 7)\n",
    "    df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "    df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "\n",
    "    df['weekofyear'] = df['영업일자'].dt.isocalendar().week.astype(int)\n",
    "    df['week_sin'] = np.sin(2*np.pi*df['weekofyear']/52)\n",
    "    df['week_cos'] = np.cos(2*np.pi*df['weekofyear']/52)\n",
    "\n",
    "    # 3) 롤링/래그\n",
    "    key = '영업장명_메뉴명'\n",
    "    g = df.groupby(key)['매출수량']\n",
    "\n",
    "    for win in [3, 7, 14, 28]:\n",
    "        df[f'rolling_avg_{win}d'] = g.apply(lambda s: s.shift(1).rolling(win, min_periods=1).mean()).reset_index(level=0, drop=True)\n",
    "        df[f'rolling_std_{win}d'] = g.apply(lambda s: s.shift(1).rolling(win, min_periods=2).std()).reset_index(level=0, drop=True)\n",
    "        df[f'rolling_sum_{win}d'] = g.apply(lambda s: s.shift(1).rolling(win, min_periods=1).sum()).reset_index(level=0, drop=True)\n",
    "\n",
    "    for lag in [1, 3, 7, 14]:\n",
    "        df[f'sales_lag_{lag}'] = g.shift(lag)\n",
    "\n",
    "    # === 추가 피처 3개 ===\n",
    "    # 1) zscore_7\n",
    "    roll_mean_7 = df['rolling_avg_7d']\n",
    "    roll_std_7  = df['rolling_std_7d']\n",
    "    y_shift1 = g.shift(1)\n",
    "    df['zscore_7'] = ((y_shift1 - roll_mean_7) / (roll_std_7 + 1e-6)).replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    # 5) === 추가: 요청한 7일 기반 피처들만 ===\n",
    "    ycol = '매출수량'\n",
    "\n",
    "    # 5-1) EWM(7)\n",
    "    df['ewm_mean_7'] = g.apply(lambda s: s.shift(1).ewm(span=7, adjust=False).mean()).reset_index(level=0, drop=True)\n",
    "\n",
    "    # 5-2) STL(7): trend_7 / seasonal_7 / resid_7\n",
    "    def _stl7(gr):\n",
    "        y = gr[ycol].fillna(0).values\n",
    "        if len(y) < 14:\n",
    "            gr['trend_7'] = 0; gr['seasonal_7'] = 0; gr['resid_7'] = 0\n",
    "            return gr\n",
    "        stl = STL(y, period=7, robust=True).fit()\n",
    "        gr['trend_7']   = stl.trend\n",
    "        gr['seasonal_7']= stl.seasonal\n",
    "        gr['resid_7']   = stl.resid\n",
    "        return gr\n",
    "    df = df.groupby(key, group_keys=False).apply(_stl7)\n",
    "\n",
    "    # 5-3) 주간 로그-기울기(추세): slope_log1p_7\n",
    "    def _roll_slope(a):\n",
    "        n = len(a)\n",
    "        if n <= 1: return 0.0\n",
    "        x = np.arange(n, dtype=np.float32)\n",
    "        y = a.astype(np.float32)\n",
    "        sx, sy = x.sum(), y.sum()\n",
    "        sxx, sxy = (x*x).sum(), (x*y).sum()\n",
    "        denom = n*sxx - sx*sx\n",
    "        return 0.0 if denom == 0 else (n*sxy - sx*sy)/denom\n",
    "\n",
    "    df['slope_log1p_7'] = g.apply(\n",
    "        lambda s: np.log1p(s.shift(1)).rolling(7, min_periods=2).apply(_roll_slope, raw=True)\n",
    "    ).reset_index(level=0, drop=True)\n",
    "\n",
    "    # 5-4) 분위수/강건 통계: q10/q90/IQR (7일)\n",
    "    g = df.groupby('영업장명_메뉴명')['매출수량']\n",
    "    q10 = g.apply(lambda s: s.shift(1).rolling(7, min_periods=1).quantile(0.10)).reset_index(level=0, drop=True)\n",
    "    q90 = g.apply(lambda s: s.shift(1).rolling(7, min_periods=1).quantile(0.90)).reset_index(level=0, drop=True)\n",
    "    q25 = g.apply(lambda s: s.shift(1).rolling(7, min_periods=1).quantile(0.25)).reset_index(level=0, drop=True)\n",
    "    q75 = g.apply(lambda s: s.shift(1).rolling(7, min_periods=1).quantile(0.75)).reset_index(level=0, drop=True)\n",
    "    \n",
    "    df['roll_q10_7'] = q10.values\n",
    "    df['roll_q90_7'] = q90.values\n",
    "    df['roll_iqr_7'] = (q75 - q25).values\n",
    "\n",
    "    # 4) 누적/주차/월차 통계 (원래 코드 유지)\n",
    "    df['cum_sales'] = df.groupby('영업장명_메뉴명')['매출수량'].cumsum()\n",
    "    df['year_week'] = df['영업일자'].dt.strftime('%Y-%U')\n",
    "    df['year_month'] = df['영업일자'].dt.strftime('%Y-%m')\n",
    "    df['weekly_avg_sales'] = df.groupby(['영업장명_메뉴명', 'year_week'])['매출수량'].transform('mean')\n",
    "    df['weekly_std_sales'] = df.groupby(['영업장명_메뉴명', 'year_week'])['매출수량'].transform('std')\n",
    "    df['weekly_sum_sales'] = df.groupby(['영업장명_메뉴명', 'year_week'])['매출수량'].transform('sum')\n",
    "    df['weekly_min_sales'] = df.groupby(['영업장명_메뉴명', 'year_week'])['매출수량'].transform('min')\n",
    "    df['weekly_max_sales'] = df.groupby(['영업장명_메뉴명', 'year_week'])['매출수량'].transform('max')\n",
    "    df['weekly_avg_shift1'] = df.groupby('영업장명_메뉴명')['weekly_avg_sales'].shift(1)\n",
    "    df['weekday_avg_sales'] = df.groupby(['메뉴명', 'weekday'])['매출수량'].transform('mean')\\\n",
    "    \n",
    "    # 1) 하락 모멘텀\n",
    "    mean7  = g.transform(lambda s: s.shift(1).rolling(7,  min_periods=1).mean())\n",
    "    y_prev1 = g.shift(1)\n",
    "    df['ratio_l1_to_mean7'] = (y_prev1 / (mean7 + 1e-6)).replace([np.inf, -np.inf], 0)\n",
    "    df['down_momentum_7']   = (1.0 - df['ratio_l1_to_mean7']).clip(lower=0)\n",
    "\n",
    "    \n",
    "    # 결측치 처리\n",
    "    num_cols = df.select_dtypes(include=['number']).columns\n",
    "    fill_cols = [c for c in num_cols if c != '매출수량']\n",
    "    for col in fill_cols:\n",
    "        df[col] = df.groupby(key)[col].transform(lambda x: x.fillna(x.median()))\n",
    "        df[col] = df.groupby(key)[col].transform(lambda x: x.ffill())\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ec8a894-afe0-49f1-aa63-32b491d8c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = feature_engineering(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "571db48d-16cc-491a-96f1-bc74bb8f8308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):  # 0부터 9까지\n",
    "    filename = f\"./data/test/TEST_0{i}.csv\"\n",
    "    df = pd.read_csv(filename).copy()\n",
    "    \n",
    "    # feature_engineering 함수 적용\n",
    "    df = feature_engineering(df)\n",
    "    \n",
    "    # 처리한 데이터 저장\n",
    "    df.to_csv(f\"./data/test_pre/TEST_0{i}.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed992d2f-6a22-4848-9bac-5fcdb50ab9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Metric & Local Validation\n",
    "# -----------------------------\n",
    "DEFAULT_STORE_WEIGHTS = {'담하': 1, '미라시아': 1}\n",
    "\n",
    "def _smape(a, p, eps=1e-12):\n",
    "    return 2.0 * np.abs(a - p) / (np.abs(a) + np.abs(p) + eps)\n",
    "\n",
    "def weighted_smape_df(df: pd.DataFrame,\n",
    "                      pred_col: str,\n",
    "                      actual_col: str,\n",
    "                      store_col: str = '영업장명',\n",
    "                      item_col: str = '영업장명_메뉴명',\n",
    "                      store_weights: dict | None = None) -> float:\n",
    "    if actual_col not in df.columns or pred_col not in df.columns:\n",
    "        return np.nan\n",
    "    valid = df[df[actual_col] != 0].copy()\n",
    "    if valid.empty:\n",
    "        return np.nan\n",
    "    valid['_smape'] = _smape(valid[actual_col].values, valid[pred_col].values)\n",
    "    total = 0.0\n",
    "    wsum  = 0.0\n",
    "    sw = store_weights or {}\n",
    "    for store, g in valid.groupby(store_col):\n",
    "        w = sw.get(store, 1.0)\n",
    "        item_means = g.groupby(item_col)['_smape'].mean()\n",
    "        if len(item_means) == 0:\n",
    "            continue\n",
    "        total += w * item_means.mean()\n",
    "        wsum  += w\n",
    "    return (total / wsum) if wsum > 0 else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b55f66-d904-49cd-b81f-6d5f9cb268c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_validate_on_test(df_test: pd.DataFrame,\n",
    "                           model,\n",
    "                           features: list,\n",
    "                           target_col: str = '매출수량',\n",
    "                           menu_col: str = '영업장명_메뉴명',\n",
    "                           store_col: str = '영업장명',\n",
    "                           date_col: str = '영업일자',\n",
    "                           store_weights: dict | None = None) -> float:\n",
    "\n",
    "    # 0) FE + 인코딩\n",
    "    df = feature_engineering(df_test.copy())\n",
    "    df = apply_cat_maps(df, cat_maps)   # ← 추가!\n",
    "\n",
    "    if date_col in df.columns:\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "        df = df.sort_values([menu_col, date_col])\n",
    "\n",
    "    # 1) 타깃 생성\n",
    "    target_cols = [f'{target_col}_tplus_{i}' for i in range(1, 8)]\n",
    "    for i in range(1, 8):\n",
    "        df[f'{target_col}_tplus_{i}'] = df.groupby(menu_col)[target_col].shift(-i)\n",
    "\n",
    "    valid = df.dropna(subset=target_cols).copy()\n",
    "    if valid.empty:\n",
    "        return np.nan\n",
    "\n",
    "    # 2) object 컬럼 제거된 features로 제한\n",
    "    features_enc = [c for c in features if c in valid.columns and valid[c].dtype != 'O']\n",
    "\n",
    "    missing = [c for c in features_enc if c not in valid.columns]\n",
    "    if missing:\n",
    "        return np.nan\n",
    "\n",
    "    Xv = valid[features_enc].values\n",
    "    yhat = model.predict(Xv)  # (n,7)\n",
    "\n",
    "    for i in range(1, 8):\n",
    "        valid[f'pred_tplus_{i}'] = yhat[:, i-1]\n",
    "\n",
    "    scores = []\n",
    "    for i in range(1, 8):\n",
    "        s = weighted_smape_df(\n",
    "            valid,\n",
    "            pred_col=f'pred_tplus_{i}',\n",
    "            actual_col=f'{target_col}_tplus_{i}',\n",
    "            store_col=store_col,\n",
    "            item_col=menu_col,\n",
    "            store_weights=store_weights\n",
    "        )\n",
    "        scores.append(s)\n",
    "    return float(np.nanmean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4cc326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_valid_files(model, features, valid_files, store_col='영업장명', menu_col='영업장명_메뉴명',\n",
    "                            date_col='영업일자', target_col='매출수량', store_weights=None):\n",
    "    scores = []\n",
    "    for path in valid_files:\n",
    "        df_te = pd.read_csv(path)\n",
    "        use_store_col = store_col if store_col in df_te.columns else menu_col\n",
    "        s = local_validate_on_test(\n",
    "            df_test=df_te,\n",
    "            model=model,\n",
    "            features=features,\n",
    "            target_col=target_col,\n",
    "            menu_col=menu_col,\n",
    "            store_col=use_store_col,\n",
    "            date_col=date_col,\n",
    "            store_weights=store_weights\n",
    "        )\n",
    "        if not np.isnan(s):\n",
    "            scores.append(s)\n",
    "    return float(np.mean(scores)) if scores else np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a1d6e-8919-48e8-845a-367d65e61e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로/상수\n",
    "TEST_DIR   = './data/test_pre'\n",
    "TEST_GLOB  = 'TEST_*.csv'\n",
    "SAMPLE_SUB = './data/sample_submission.csv'\n",
    "DATE_COL   = '영업일자'\n",
    "TARGET_COL = '매출수량'\n",
    "MENU_COL   = '영업장명_메뉴명'\n",
    "STORE_COL  = '영업장명'\n",
    "\n",
    "train[DATE_COL] = pd.to_datetime(train[DATE_COL], errors='coerce')\n",
    "\n",
    "# feature/target 구성\n",
    "features = [c for c in train.columns if c not in [TARGET_COL, DATE_COL]]\n",
    "target_cols = [f'{TARGET_COL}_tplus_{i}' for i in range(1, 8)]\n",
    "if not all(c in train.columns for c in target_cols):\n",
    "    train = train.sort_values([MENU_COL, DATE_COL]).copy()\n",
    "    for i in range(1, 8):\n",
    "        train[f'{TARGET_COL}_tplus_{i}'] = train.groupby(MENU_COL)[TARGET_COL].shift(-i)\n",
    "train = train.dropna(subset=target_cols).reset_index(drop=True)\n",
    "X_train = train[features].values\n",
    "Y_train = train[target_cols].values\n",
    "\n",
    "# 튜닝 검증 세트(파일)\n",
    "import glob, os, re\n",
    "all_test_files = sorted(glob.glob(os.path.join(TEST_DIR, TEST_GLOB)))\n",
    "valid_files = all_test_files[-2:] if len(all_test_files) >= 2 else all_test_files\n",
    "print('[INFO] valid files for tuning:', [os.path.basename(p) for p in valid_files])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71df985",
   "metadata": {},
   "source": [
    "## Optuna Objective (XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_objective_xgb(X_train, Y_train, features, valid_files):\n",
    "    def objective(trial):\n",
    "        lr = trial.suggest_float('learning_rate', 0.008, 0.25, log=True)\n",
    "        params = {\n",
    "            'n_estimators'     : trial.suggest_int('n_estimators', 300, 1600, step=100),\n",
    "            'learning_rate'    : lr,\n",
    "            'max_depth'        : trial.suggest_int('max_depth', 3, 12),\n",
    "            'min_child_weight' : trial.suggest_float('min_child_weight', 0.5, 15.0),\n",
    "            'gamma'            : trial.suggest_float('gamma', 0.0, 5.0),            # ★ 추가\n",
    "            'subsample'        : trial.suggest_float('subsample', 0.55, 1.0),\n",
    "            'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.55, 1.0),\n",
    "            'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.6, 1.0), # ★ 추가\n",
    "            'colsample_bynode' : trial.suggest_float('colsample_bynode', 0.6, 1.0),  # ★ 추가\n",
    "            'reg_alpha'        : trial.suggest_float('reg_alpha', 1e-4, 20.0, log=True),\n",
    "            'reg_lambda'       : trial.suggest_float('reg_lambda', 1e-4, 20.0, log=True),\n",
    "            'max_bin'          : trial.suggest_int('max_bin', 256, 512),             # ★ 추가\n",
    "            'n_jobs'           : 1,\n",
    "            'random_state'     : 42,\n",
    "        }\n",
    "        base = xgb.XGBRegressor(\n",
    "            tree_method='hist',\n",
    "            objective='reg:squarederror',\n",
    "            **params\n",
    "        )\n",
    "        model = MultiOutputRegressor(base)\n",
    "        model.fit(X_train, Y_train)\n",
    "        # 점포 가중치도 함께 탐색\n",
    "        w_damha   = trial.suggest_float('w_담하', 1.0, 10.0)\n",
    "        w_mirasia = trial.suggest_float('w_미라시아', 1.0, 10.0)\n",
    "        store_weights = {'담하': w_damha, '미라시아': w_mirasia}\n",
    "        score = evaluate_on_valid_files(model, features, valid_files, store_col=STORE_COL,\n",
    "                                        menu_col=MENU_COL, date_col=DATE_COL, target_col=TARGET_COL,\n",
    "                                        store_weights=store_weights)\n",
    "        return score\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f162ed39-d464-4428-aa63-ac776c327952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 카테고리 인코딩 (XGB/LGBM용) ===\n",
    "# (튜닝/학습 셀 위에 두세요)\n",
    "\n",
    "# 1) 카테고리 후보 (존재하는 것만 사용)\n",
    "cand_cat = ['영업장명_메뉴명','영업장명','메뉴명','dow_month','year_week','year_month']\n",
    "cat_cols = [c for c in cand_cat if c in train.columns]\n",
    "# object dtype 컬럼도 추가 (중복 제거)\n",
    "cat_cols += [c for c in train.select_dtypes('object').columns if c not in cat_cols]\n",
    "cat_cols = list(dict.fromkeys(cat_cols))\n",
    "\n",
    "print('[INFO] categorical columns:', cat_cols)\n",
    "\n",
    "# 2) (train + 모든 test_pre) 값의 합집합으로 카테고리 맵 생성 → unknown은 -1 처리\n",
    "import glob, os\n",
    "\n",
    "def build_cat_maps(train_df, test_dir=TEST_DIR, pattern=TEST_GLOB):\n",
    "    values = {c:set(train_df[c].dropna().astype(str).unique()) for c in cat_cols}\n",
    "    for path in glob.glob(os.path.join(test_dir, pattern)):\n",
    "        te = pd.read_csv(path)\n",
    "        te = feature_engineering(te)\n",
    "        for c in cat_cols:\n",
    "            if c in te.columns:\n",
    "                values[c].update(te[c].dropna().astype(str).unique())\n",
    "    # 안정적인 정렬(옵션): 정렬/미정렬 아무거나 사용 가능\n",
    "    maps = {c:{v:i for i, v in enumerate(sorted(values[c]))} for c in cat_cols}\n",
    "    return maps\n",
    "\n",
    "cat_maps = build_cat_maps(train)\n",
    "\n",
    "def apply_cat_maps(df, maps):\n",
    "    df = df.copy()\n",
    "    for c, m in maps.items():\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(str).map(m).fillna(-1).astype(int)\n",
    "    return df\n",
    "\n",
    "# 3) 학습 데이터 인코딩 후 X/Y 재생성\n",
    "train_enc = apply_cat_maps(train, cat_maps)\n",
    "\n",
    "# 타깃 파생 접두어\n",
    "forbidden_prefix = f'{TARGET_COL}_tplus_'\n",
    "\n",
    "# 인코딩된 train_enc 기준으로 features 재구성\n",
    "features = [\n",
    "    c for c in train_enc.columns\n",
    "    if (c not in [TARGET_COL, DATE_COL])      # 원 타깃/날짜 제외\n",
    "    and (not c.startswith(forbidden_prefix))  # 매출수량_tplus_* 제외\n",
    "    and (train_enc[c].dtype != 'O')            # object 제외\n",
    "]\n",
    "\n",
    "# 학습 데이터 다시 만들기\n",
    "X_train = train_enc[features].values\n",
    "target_cols = [f'{TARGET_COL}_tplus_{i}' for i in range(1, 8)]\n",
    "Y_train = train_enc[target_cols].values\n",
    "\n",
    "print('[INFO] len(features)=', len(features))\n",
    "assert not any(c.startswith(forbidden_prefix) for c in features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a9da5",
   "metadata": {},
   "source": [
    "## Run Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafbffe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(make_objective_xgb(X_train, Y_train, features, valid_files), n_trials=100, show_progress_bar=True)\n",
    "print('[BEST] params:', study.best_params)\n",
    "print('[BEST] score :', study.best_value)\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "best_store_weights = {'담하': best_params.pop('w_담하'), '미라시아': best_params.pop('w_미라시아')}\n",
    "print('[INFO] final store weights:', best_store_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc634c32-5fde-45fe-becf-11be0180c657",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_model = MultiOutputRegressor(xgb.XGBRegressor(\n",
    "    tree_method='hist',\n",
    "    objective='reg:squarederror',\n",
    "    **best_params\n",
    "))\n",
    "final_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ec4ff2",
   "metadata": {},
   "source": [
    "## Predict & Build Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a451d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows = []\n",
    "for path in all_test_files:\n",
    "    df_te = pd.read_csv(path)\n",
    "\n",
    "    # 1) FE\n",
    "    df_te = feature_engineering(df_te)\n",
    "    # 원본 메뉴명 보존\n",
    "    df_te['menu_orig'] = df_te[MENU_COL].astype(str)\n",
    "\n",
    "    # 2) 인코딩\n",
    "    df_te_enc = apply_cat_maps(df_te, cat_maps)\n",
    "    # 인코딩 후에도 원본 메뉴명 열 유지\n",
    "    df_te_enc['menu_orig'] = df_te['menu_orig'].values\n",
    "\n",
    "    # 3) 피처 보강/숫자화\n",
    "    for col in features:\n",
    "        if col not in df_te_enc.columns:\n",
    "            df_te_enc[col] = 0\n",
    "    df_te_enc[features] = df_te_enc[features].apply(pd.to_numeric, errors='coerce').fillna(0).astype('float32')\n",
    "\n",
    "    # 4) 날짜 처리\n",
    "    if DATE_COL in df_te_enc.columns:\n",
    "        df_te_enc[DATE_COL] = pd.to_datetime(df_te_enc[DATE_COL], errors='coerce')\n",
    "\n",
    "    fname = os.path.basename(path)\n",
    "    m = re.search(r'(TEST_\\d+)', fname); test_prefix = m.group(1) if m else 'TEST_??'\n",
    "\n",
    "    # ▶ 그룹바이 기준을 'menu_orig'(문자열)로!\n",
    "    for menu_name, sub in df_te_enc.groupby('menu_orig'):\n",
    "        sub = sub.sort_values(DATE_COL) if DATE_COL in sub.columns else sub\n",
    "        X_last = sub[features].tail(1).to_numpy(dtype=np.float32, copy=False)\n",
    "        yhat = final_model.predict(X_last).ravel()\n",
    "        yhat = np.clip(yhat, 0, None)\n",
    "\n",
    "        for k in range(7):\n",
    "            all_rows.append({\n",
    "                '영업일자': f'{test_prefix}+{k+1}일',\n",
    "                '영업장명_메뉴명': menu_name,   # ← 문자열 이름으로 저장\n",
    "                '매출수량': float(yhat[k])\n",
    "            })\n",
    "\n",
    "full_pred_df = pd.DataFrame(all_rows, columns=['영업일자','영업장명_메뉴명','매출수량'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d55c909-88c2-42b7-8379-fe363b72174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3309eb72-1702-4ef0-a510-b27af439ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pred_df.to_csv('./data/xgb7.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc52efba-f6d8-465c-9ce1-4365c8450f60",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee79911-01fc-42cd-a5c3-ecd501029227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_submission_format(pred_df: pd.DataFrame, sample_submission: pd.DataFrame):\n",
    "    pred_dict = dict(zip(\n",
    "        zip(pred_df['영업일자'], pred_df['영업장명_메뉴명']),\n",
    "        pred_df['매출수량']\n",
    "    ))\n",
    "    final_df = sample_submission.copy()\n",
    "    for row_idx in final_df.index:\n",
    "        date = final_df.loc[row_idx, '영업일자']\n",
    "        for col in final_df.columns[1:]:\n",
    "            final_df.loc[row_idx, col] = pred_dict.get((date, col), 0)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061b0861-baba-40e8-ba6f-76731b0ef9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(SAMPLE_SUB)\n",
    "submission = convert_to_submission_format(full_pred_df, sample_submission)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('Gonjiam_submission_XGB7.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8f90f-2c55-4b10-86e9-784639dd7785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
